<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="DDAVS: Disentangled Audio Semantics and Delayed Bidirectional Alignment for Audio-Visual Segmentation">
  <meta name="keywords" content="DDAVS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DDAVS: Disentangled Audio Semantics and Delayed Bidirectional Alignment for Audio-Visual Segmentation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.ico"> -->
  <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- <h3 class="title is-3 publication-title" style="color: #FF0000; ">
              <b>[ACL 2025 Findings]</b>
            </h3> -->
            <h1 class="title is-1 publication-title">
               <span style="color: #177cb0;">DDAVS</span>:
              Disentangled Audio Semantics and Delayed Bidirectional Alignment for Audio-Visual Segmentation
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://trilarflagz.github.io/">Jingqi Tian</a><sup>1</sup>,</span>
              <span class="author-block">
                <!-- <a href="https://ideny42.github.io/"> -->
                  Yiheng Du</a><sup>2</sup>,</span>                
              <span class="author-block">
                <a href="https://zhang9302002.github.io/">Haoji Zhang</a><sup>1</sup>,</span>                
              <span class="author-block">                
                <a href="https://voyagewang.github.io/">Yuji Wang</a><sup>1</sup>,</span>
              <span class="author-block">
                Isaac Ning Lee</a><sup>1</sup>,</span>
              <span class="author-block">
                Xulong Bai</a><sup>1</sup>,</span>                
              <span class="author-block">
                <a href="https://xilluill.github.io/">Tianrui Zhu</a><sup>1</sup>,</span>
              <span class="author-block">
                Jingxuan Niu</a><sup>1</sup>,</span>                
              <span class="author-block">
                <a href="https://andytang15.github.io/">Yansong Tang</a><sup>1&#9993;</sup></span>                
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tsinghua University,</span>
              <span class="author-block"><sup>2</sup>Peking University.</span>
            </div>

            <div class="is-size-5 publication-authors">
              <!-- <span class="author-block"><sup>*</sup>Equal contribution,</span> -->
              <span class="author-block"><sup>&#9993;</sup>Corresponding authors.</span>
              <!-- <span class="author-block"><sup>&dagger;</sup>Project leader.</span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code & Model (coming soon)</span>
                  </a>
                </span>
          
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- <div class="content has-text-centered">
    <img src="./static/images/teaser.png" alt="DDAVS Teaser" width="35%">
    <figcaption>
      <strong>Qualitative comparison of our DDAVS model and previous methods.<br>  
            DDAVS consistently outperforms previous approaches in challenging scenarios involving <br> 
           multiple classes, multiple sources, small or distant sound sources, and off-screen audio cues.</strong>
      </strong>
    </figcaption>
  </div> -->

  <div class="content has-text-centered">
    <img src="./static/images/method_compare.png" alt="DDAVS method_compare" width="32%">
    <figcaption>
      <div style="display: inline-block; text-align: left;"></div>
        <strong>
    For audio disentanglement, (a‚Äìb) rely on learned queries or K-nearest-class features,<br>
    while (c) grounds audio queries in a prototype memory bank with contrastive refinement.<br>
    For audio-visual alignment, (d‚Äìe) treat audio as a fixed or gated condition,<br>
    while (f) uses delayed dual cross-attention for more robust multimodal alignment.
        </strong>
      </div>  
    </figcaption>
  </div>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- TL;DR. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">TL;DR</h2>
          <div class="content has-text-justified">
            <p>
            <strong>
              We propose DDAVS, an audio-visual segmentation framework that disentangles audio semantics and performs
              delayed bidirectional modality alignment to robustly localize sounding objects at the pixel level.
              DDAVS introduces an Audio Query Module with a prototype memory bank, a contrastive optimization module, and a multi-stage Audio-Visual Alignment Module,
              achieving state-of-the-art performance on AVS-Objects and VPO benchmarks, especially in challenging multi-source, subtle, distant, and off-screen scenarios.
            </strong>
            </p>
          </div>
        </div>
      </div>
      <!--/ TL;DR. -->


      <div class="content has-text-centered">
        <img src="./static/images/teaser.png" alt="DDAVS Teaser" width="80%">
        <figcaption>
          <strong>
            DDAVS consistently outperforms previous approaches in challenging scenarios.
          </strong>
        </figcaption>
      </div>

      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Audio‚ÄìVisual Segmentation (AVS) aims to localize sound-producing objects at the pixel level by jointly leveraging
              auditory and visual information. However, existing methods often suffer from multi-source entanglement and
              audio‚Äìvisual misalignment, which lead to biases toward louder or larger objects while overlooking weaker, smaller,
              or co-occurring sources. To address these challenges, we propose DDAVS, a
              Disentangled Audio Semantics and Delayed Bidirectional Alignment framework. To mitigate multi-source entanglement,
              DDAVS employs learnable queries to extract audio semantics and anchor them within a structured semantic space derived
              from an audio prototype memory bank. This is further optimized through contrastive learning to enhance discriminability
              and robustness. To alleviate audio‚Äìvisual misalignment, DDAVS introduces dual cross-attention with delayed modality
              interaction, improving the robustness of multimodal alignment. Extensive experiments on the AVS-Objects and VPO
              benchmarks demonstrate that DDAVS consistently outperforms existing approaches, exhibiting strong performance across
              single-source, multi-source, and multi-instance scenarios. These results validate the effectiveness and generalization
              ability of our framework under challenging real-world audio‚Äìvisual segmentation conditions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">

      <!-- Main text. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">Pipeline</h2>

          <div class="content has-text-justified">
            <p>
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/overview.png" alt="Pipeline" width="80%">
            <figcaption>
              <strong>Overview of DDAVS framework.</strong>
              (a) The Audio Query Module (AQM) encodes original and augmented <br>waveforms 
              into disentangled semantic queries anchored to a prototype memory bank.
              (b) The Contrastive <br>Optimization Module (COM) enhances query robustness through contrastive learning,
               used only during <br>training.
              (c) The Audio-Visual Alignment Module (AVAM) fuses audio queries with visual features via stacked <br>alignment blocks, 
               and a lightweight decoder outputs the sound-conditioned segmentation masks.
            </figcaption>

          </div>

          <h2 class="title is-3 has-text-centered">Results</h2>

          <div class="content has-text-centered">
            <img src="./static/images/results1.png" alt="Results" width="80%">
          </div>

          <div class="content has-text-centered">
            <img src="./static/images/results2.png" alt="Results" width="80%">
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/results3.png" alt="Results" width="80%">
          </div>


          <h2 class="title is-3 has-text-centered">Ablation Studies</h2>

          <div class="content has-text-centered">
            <img src="./static/images/ablation.png" alt="Results" width="80%">
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/ablation3.png" alt="Results" width="80%">
          </div>

          <h2 class="title is-3 has-text-centered">Case Study</h2>

          <div class="content has-text-centered">
            <img src="./static/images/case_study.png" alt="Results" width="70%">
            <figcaption>
              <strong>Case study of DDAVS on Multi-class tasks.</strong>
            </figcaption>
          </div>

        </div>
      </div>
    </div>
  </section>

  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{ponderpress,
        title={Ponder & Press: Advancing Visual GUI Agent towards General Computer Control},
        author={Wang, Yiqin and Zhang, Haoji and Tian, Jingqi and Tang, Yansong},
        journal={arXiv preprint arXiv:2412.01268},
        year={2024}
  }</code></pre>
    </div>
  </section> -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              &copy; Jingqi Tian 2025. Adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>